{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6517f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "import os\n",
    "import glob \n",
    "import re\n",
    "from obspy.io.sac import SACTrace\n",
    "from obspy import read_inventory, UTCDateTime\n",
    "from obspy.clients.iris import Client\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b8b654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '0_get_events.ipynb',\n",
       " '1_get_stations.ipynb',\n",
       " '2_plot_evtsta.ipynb',\n",
       " '3_get_waveform.ipynb',\n",
       " '3_get_waveform_2001.ipynb',\n",
       " 'Download',\n",
       " 'Download.png',\n",
       " 'Events',\n",
       " 'ISC_EHB_Catalog_1980-2018',\n",
       " 'README.md',\n",
       " 'Stations']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client()\n",
    "root_dir = \"/media/elemento/Element/NTU_RW/NEFS\"\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ab0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read all the events one-by-one, stored in the catalog ...\n",
    "# ... and store them in variables\n",
    "\n",
    "def read_evt_NEFS(evtf):\n",
    "    \"\"\"Read event information\"\"\"\n",
    "    with open(evtf, 'r') as f:\n",
    "        lines = f.readlines()[0:]\n",
    "        events = []\n",
    "        dnames = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            temp = line.split()\n",
    "            t = UTCDateTime(temp[0])\n",
    "            lat, lon = float(temp[1]), float(temp[2])\n",
    "            depth = float(temp[3])\n",
    "            mag = float(temp[4])\n",
    "            events.append([t, lat, lon, depth, mag])\n",
    "            dnames.append(\"\".join(temp[0].split(\"T\")[0].split(\"-\")) + \"\".join(\"\".join(\"\".join(temp[0].split(\"T\")[1].split(\"Z\")).split(\".\")).split(\":\")))\n",
    "        return dnames, events\n",
    "\n",
    "def read_evt_NSFE(evtf):\n",
    "    \"\"\"Read event information\"\"\"\n",
    "    with open(evtf, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "        events = []\n",
    "        dnames = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            temp = line.split(',')\n",
    "            t = UTCDateTime(temp[0])\n",
    "            lat, lon = float(temp[1]), float(temp[2])\n",
    "            depth = float(temp[3])\n",
    "            mag = float(temp[5])\n",
    "            events.append([t, lat, lon, depth, mag])\n",
    "            dnames.append(\"\".join(temp[0].split(\"T\")[0].split(\"-\")) + \"\".join(\"\".join(\"\".join(temp[0].split(\"T\")[1].split(\"Z\")).split(\".\")).split(\":\")))\n",
    "        return dnames, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e852fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mseed2sac(data_root, data_out, data_staxml, dnames, events):\n",
    "    \"\"\"Convert miniseed to SAC\"\"\"\n",
    "    \n",
    "    # Iterating over all the events\n",
    "    for evt in zip(dnames, events):\n",
    "        rootd = os.path.join(data_root, evt[0])\n",
    "        if not os.path.exists(rootd):\n",
    "            continue\n",
    "        else:\n",
    "            outd = os.path.join(data_out, evt[0])\n",
    "            if not os.path.exists(outd):\n",
    "                os.makedirs(outd)\n",
    "            \n",
    "            # Moving into the folder of a single event\n",
    "            # Selecting only the mseed files containing the Z component \n",
    "            fpath = os.path.join(data_root, evt[0])\n",
    "            os.chdir(fpath)\n",
    "            files = glob.glob(\"*Z.mseed\")\n",
    "            \n",
    "            # Reading the selected files one-by-one\n",
    "            for file in files:\n",
    "                stanm = \"{}.{}.{}.{}\".format(file.split(\".\")[0],file.split(\".\")[1],file.split(\".\")[2],file.split(\".\")[3])\n",
    "                if os.path.exists(\"{}/{}/{}.SAC\".format(data_out, evt[0], stanm)):\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        st = obspy.read(file)\n",
    "                        tr = st[0]\n",
    "                        outfile = \"{}.{}\".format(tr.stats.network,tr.stats.station)\n",
    "                        print(\"{} {}\".format(evt[0],outfile))\n",
    "                        \n",
    "                        # Reading the metadata for the corresponding station ...\n",
    "                        # ... of this particular data\n",
    "                        stas = read_inventory(f\"{data_staxml}/{outfile}.xml\")\n",
    "\n",
    "                        if (tr.stats.channel==stas[0][0][0].code):\n",
    "                            stas[0][0][0].location_code = tr.stats.location\n",
    "                        elif (tr.stats.channel==stas[0][0][1].code):\n",
    "                            stas[0][0][1].location_code = tr.stats.location\n",
    "                        else :\n",
    "                            stas[0][0][2].location_code = tr.stats.location\n",
    "\n",
    "                        # https://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.remove_response.html\n",
    "                        # Remove the response, and in order to do that, we need the metadata for the ...\n",
    "                        # ... corresponding station\n",
    "                        trace = tr.copy()\n",
    "                        try:\n",
    "                            trace.remove_response(inventory=stas) \n",
    "                        except ValueError:\n",
    "                            print(\"No meaningful response File: %s\" % outfile)\n",
    "                            continue\n",
    "\n",
    "                        # Convert to SACTrace from ObsPy Trace\n",
    "                        sactr = SACTrace.from_obspy_trace(trace)\n",
    "\n",
    "                        # Set event origin time as SAC reference time\n",
    "                        sactr.reftime = evt[1][0]\n",
    "                        sactr.o = 0\n",
    "                        sactr.iztype = 'io'\n",
    "\n",
    "                        # Set event location and magnitude\n",
    "                        sactr.evla = evt[1][1]\n",
    "                        sactr.evlo = evt[1][2]\n",
    "                        sactr.evdp = evt[1][3]\n",
    "                        sactr.mag = evt[1][4]\n",
    "\n",
    "                        # Set station location // network, station\n",
    "                        sactr.stla = stas[0][0][0].latitude\n",
    "                        sactr.stlo = stas[0][0][0].longitude\n",
    "                        sactr.stel = stas[0][0][0].elevation\n",
    "                        sactr.knetwk = stas[0].code\n",
    "                        sactr.kstnm = stas[0][0].code\n",
    "\n",
    "                        # https://docs.obspy.org/packages/autogen/obspy.io.sac.sactrace.SACTrace.html\n",
    "                        # Set cmpaz, cmpinc, kcmpnm where ...\n",
    "                        # cmpaz = Component azimuth (degrees, clockwise from north)\n",
    "                        # cmpinc = Component incident angle (degrees, from vertical)\n",
    "                        # kcmpnm = Component name\n",
    "                        if (tr.stats.channel==stas[0][0][0].code):\n",
    "                            sactr.cmpaz = stas[0][0][0].azimuth\n",
    "                            sactr.cmpinc = stas[0][0][0].dip\n",
    "                            sactr.kcmpnm = stas[0][0][0].code\n",
    "                        elif (tr.stats.channel==stas[0][0][1].code):\n",
    "                            sactr.cmpaz = stas[0][0][1].azimuth\n",
    "                            sactr.cmpinc = stas[0][0][1].dip\n",
    "                            sactr.kcmpnm = stas[0][0][1].code\n",
    "                        else :\n",
    "                            sactr.cmpaz = stas[0][0][2].azimuth\n",
    "                            sactr.cmpinc = stas[0][0][2].dip\n",
    "                            sactr.kcmpnm = stas[0][0][2].code\n",
    "\n",
    "                        # Other SAC headers\n",
    "                        # TRUE if DIST AZ BAZ and GCARC are to be calculated from st event coordinates.\n",
    "                        sactr.lcalda = 1  \n",
    "\n",
    "                        # DIST AZ BAZ and GCARC headers will be calculated from station and event coordinates.\n",
    "                        # Note that thing may not be same if we use ObsPy Trace.\n",
    "\n",
    "                        # Write to sac files\n",
    "                        sactr.write(os.path.join(outd, tr.id + '.SAC'))\n",
    "\n",
    "                        clear_output(wait=False)\n",
    "                        \n",
    "                    except:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f60812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "providers = [\"IRIS\", \"GFZ\"]\n",
    "years = [2010, 2011, 2012, 2013, 2014]\n",
    "\n",
    "for year1 in years:\n",
    "    year2 = year1 + 1\n",
    "    for provider in providers:\n",
    "        print(f\"For the range: {year1}-{year2}, and provider: {provider}\")\n",
    "        \n",
    "        data_mseed = f'{root_dir}/Download/{provider}/miniseed/{year1}'    \n",
    "        data_staxml = f'{root_dir}/Download/{provider}/stations/{year1}'\n",
    "        data_sac = f'{root_dir}/Download/{provider}/SAC/{year1}'\n",
    "\n",
    "        ### NEFS data catalog\n",
    "        evt_lst = f'{root_dir}/Events/Catalog_{year1}-{year2}'   \n",
    "\n",
    "        ### NSFE data catalog\n",
    "        # evt_lst = f'{root_dir}/events_{year1}-{year2}.csv'  \n",
    "\n",
    "        if not os.path.exists(data_sac):\n",
    "            os.makedirs(data_sac)\n",
    "\n",
    "        # Read event metadata\n",
    "        ### Using this to read catalog file when processing NEFS data\n",
    "        dnames, events = read_evt_NEFS(evt_lst) \n",
    "\n",
    "        ### Using this to read catalog file when processing NSFE data\n",
    "        # dnames, events = read_evt_NSFE(evt_lst)  \n",
    "\n",
    "        # Convert miniseed to sac\n",
    "        mseed2sac(data_mseed, data_sac, data_staxml, dnames, events)\n",
    "        \n",
    "        clear_output(wait=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15a3f4c3e6dce4ef769870110c74abcd276220084a34a799f01cf6244fa3cec2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
